{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction\n",
    "This ML Model will be used to predict passenger survival based on the dataset from Kaggle (https://www.kaggle.com/competitions/titanic). In this approach, we will be using a Tensorflow/Keras DNN to perform predictions on the test.csv file after training with the supplied train.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries/Modules\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets open the csv file and preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CSV Filepath\n",
    "train_data_path = 'Data/train.csv'\n",
    "test_data_path = 'Data/test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_data_path, delimiter=',')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 891 rows of training data. As seen from above, the data requires cleaning & preprocessing before it can be fed into a Neural Network. \n",
    "\n",
    "First, we will drop the columns which are not relevant to training:\n",
    "- PassengerId: We do not require the Passenger Id for training our model since it is just an index.\n",
    "- Name: The name of the passenger is not required as it has no impact on the result.\n",
    "- Ticket: This is just the ticket number, again this should not have an impact on the result.\n",
    "- Cabin: This may have an impact on the result, however there are a large number of rows without a cabin value (only 204 out of 890) so this will be discarded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0           0       3    male  22.0      1      0   7.2500        S\n",
       "1           1       1  female  38.0      1      0  71.2833        C\n",
       "2           1       3  female  26.0      0      0   7.9250        S\n",
       "3           1       1  female  35.0      1      0  53.1000        S\n",
       "4           0       3    male  35.0      0      0   8.0500        S\n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...\n",
       "886         0       2    male  27.0      0      0  13.0000        S\n",
       "887         1       1  female  19.0      0      0  30.0000        S\n",
       "888         0       3  female   NaN      1      2  23.4500        S\n",
       "889         1       1    male  26.0      0      0  30.0000        C\n",
       "890         0       3    male  32.0      0      0   7.7500        Q\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to handle null values for the remaining columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, it is evident that there are a significant number of rows without age. We have two options here - either discard null rows OR fill in the values using some statistical approaches like mean, mode etc. Since we only have around 800 rows of data, dropping ~170 rows would affect our training, so we will instead fill in with mean.\n",
    "For the other column 'Embarked', we can just drop the rows since there are only 2 rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/j0q38tb53cddks5lvhm9vjlc0000gn/T/ipykernel_2607/1827510441.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
       "0           0       3    male  22.000000      1      0   7.2500        S\n",
       "1           1       1  female  38.000000      1      0  71.2833        C\n",
       "2           1       3  female  26.000000      0      0   7.9250        S\n",
       "3           1       1  female  35.000000      1      0  53.1000        S\n",
       "4           0       3    male  35.000000      0      0   8.0500        S\n",
       "..        ...     ...     ...        ...    ...    ...      ...      ...\n",
       "886         0       2    male  27.000000      0      0  13.0000        S\n",
       "887         1       1  female  19.000000      0      0  30.0000        S\n",
       "888         0       3  female  29.642093      1      2  23.4500        S\n",
       "889         1       1    male  26.000000      0      0  30.0000        C\n",
       "890         0       3    male  32.000000      0      0   7.7500        Q\n",
       "\n",
       "[889 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.dropna(subset=['Embarked'])\n",
    "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical Values\n",
    "For the columns with categorical values, we will perform one-hot encoding. Note that this is feasible only if the number of categories is not very large, because the cardinality of the dataset will increase. One-hot encoding is done to prevent the model from misinterpreting data (e.g. the model might think a pclass of 3 is greater than a pclass of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived        Age  SibSp  Parch     Fare  female  male  Pclass_1  \\\n",
       "0           0  22.000000      1      0   7.2500       0     1         0   \n",
       "1           1  38.000000      1      0  71.2833       1     0         1   \n",
       "2           1  26.000000      0      0   7.9250       1     0         0   \n",
       "3           1  35.000000      1      0  53.1000       1     0         1   \n",
       "4           0  35.000000      0      0   8.0500       0     1         0   \n",
       "..        ...        ...    ...    ...      ...     ...   ...       ...   \n",
       "886         0  27.000000      0      0  13.0000       0     1         0   \n",
       "887         1  19.000000      0      0  30.0000       1     0         1   \n",
       "888         0  29.642093      1      2  23.4500       1     0         0   \n",
       "889         1  26.000000      0      0  30.0000       0     1         1   \n",
       "890         0  32.000000      0      0   7.7500       0     1         0   \n",
       "\n",
       "     Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0         1           0           0           1  \n",
       "1           0         0           1           0           0  \n",
       "2           0         1           0           0           1  \n",
       "3           0         0           0           0           1  \n",
       "4           0         1           0           0           1  \n",
       "..        ...       ...         ...         ...         ...  \n",
       "886         1         0           0           0           1  \n",
       "887         0         0           0           0           1  \n",
       "888         0         1           0           0           1  \n",
       "889         0         0           1           0           0  \n",
       "890         0         1           0           1           0  \n",
       "\n",
       "[889 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One-hot encoding the 'Sex' column\n",
    "train_data = pd.concat([train_data, pd.get_dummies(train_data['Sex'])],axis=1)\n",
    "#One-hot encoding the 'Pclass' column\n",
    "train_data = pd.concat([train_data, pd.get_dummies(train_data['Pclass'], prefix='Pclass')],axis=1)\n",
    "#One-hot encoding the 'Embarked' column\n",
    "train_data = pd.concat([train_data, pd.get_dummies(train_data['Embarked'], prefix='Embarked')],axis=1)\n",
    "\n",
    "#Dropping original columns since they are now encoded\n",
    "train_data = train_data.drop(['Pclass','Sex','Embarked'], axis=1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been cleaned, this will be our final dataset! The labels will be the first column (shape 888x1) and the input will be the remaining columns (input vector shape 888x12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables to store final vectors\n",
    "train_input = []\n",
    "train_labels = []\n",
    "for index,row in train_data.iterrows() :\n",
    "    #Append 1st column to labels\n",
    "    train_labels.append(row['Survived'])\n",
    "    #Append remaining columns to input\n",
    "    train_input.append(row[1:])\n",
    "\n",
    "#Convert to NP Arrays\n",
    "train_input = np.asarray(train_input)\n",
    "train_labels = np.asarray(train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "For this problem, we will be using a DNN model with the Keras Sequential API. The model architecture will comprise of:\n",
    "- 1 Input Layer of 12 neurons\n",
    "- 2 Hidden Layers of 12,6 neurons \n",
    "- 1 Output Layer of 1 neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, None, 12)          156       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, None, 12)          156       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, None, 6)           78        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, None, 1)           7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 397\n",
      "Trainable params: 397\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(173342) #Set seed for reproducability\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    #Input Layer\n",
    "    tf.keras.layers.Dense(12,input_shape=(None,12),activation=\"relu\"),\n",
    "    #1st Hidden Layer\n",
    "    tf.keras.layers.Dense(12,activation=\"relu\"),\n",
    "    #2nd Hidden Layer\n",
    "    tf.keras.layers.Dense(6,activation=\"relu\"),\n",
    "    #Output Layer which using sigmoid (because we just have two output classes)\n",
    "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "#print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "We will train the model for 200 epochs and a batch size of 20. The optimizer used will be Adam (default learning rate) with the Binary Cross-Entropy Loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 12) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 12), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (None, 12).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 12) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 12), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (None, 12).\n",
      " 8/45 [====>.........................] - ETA: 0s - loss: 6.9444 - accuracy: 0.3812 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 10:42:40.490763: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 8ms/step - loss: 3.8548 - accuracy: 0.4106\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.7938 - accuracy: 0.6704\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.6544 - accuracy: 0.6727\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.6170 - accuracy: 0.6828\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.6131 - accuracy: 0.6738\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.6011 - accuracy: 0.6884\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5960 - accuracy: 0.6828\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5910 - accuracy: 0.6895\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5844 - accuracy: 0.6850\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5785 - accuracy: 0.6828\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5733 - accuracy: 0.6929\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5693 - accuracy: 0.6929\n",
      "Epoch 13/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5707 - accuracy: 0.6862\n",
      "Epoch 14/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5614 - accuracy: 0.7244\n",
      "Epoch 15/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5645 - accuracy: 0.7143\n",
      "Epoch 16/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.7154\n",
      "Epoch 17/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5385 - accuracy: 0.7210\n",
      "Epoch 18/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5274 - accuracy: 0.7210\n",
      "Epoch 19/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5227 - accuracy: 0.7267\n",
      "Epoch 20/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5141 - accuracy: 0.7413\n",
      "Epoch 21/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5097 - accuracy: 0.7435\n",
      "Epoch 22/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5040 - accuracy: 0.7615\n",
      "Epoch 23/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4974 - accuracy: 0.7683\n",
      "Epoch 24/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4899 - accuracy: 0.7705\n",
      "Epoch 25/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4984 - accuracy: 0.7750\n",
      "Epoch 26/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4935 - accuracy: 0.7705\n",
      "Epoch 27/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4773 - accuracy: 0.7930\n",
      "Epoch 28/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4757 - accuracy: 0.7739\n",
      "Epoch 29/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4675 - accuracy: 0.7807\n",
      "Epoch 30/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.7795\n",
      "Epoch 31/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4613 - accuracy: 0.7885\n",
      "Epoch 32/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4626 - accuracy: 0.7919\n",
      "Epoch 33/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4584 - accuracy: 0.7818\n",
      "Epoch 34/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4512 - accuracy: 0.7840\n",
      "Epoch 35/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4435 - accuracy: 0.8031\n",
      "Epoch 36/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4480 - accuracy: 0.7897\n",
      "Epoch 37/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4516 - accuracy: 0.7987\n",
      "Epoch 38/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.8043\n",
      "Epoch 39/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.7964\n",
      "Epoch 40/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.7987\n",
      "Epoch 41/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.8166\n",
      "Epoch 42/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.8088\n",
      "Epoch 43/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4346 - accuracy: 0.8031\n",
      "Epoch 44/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8133\n",
      "Epoch 45/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.8054\n",
      "Epoch 46/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8110\n",
      "Epoch 47/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.8099\n",
      "Epoch 48/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8110\n",
      "Epoch 49/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.8155\n",
      "Epoch 50/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4300 - accuracy: 0.8099\n",
      "Epoch 51/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8043\n",
      "Epoch 52/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8144\n",
      "Epoch 53/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8144\n",
      "Epoch 54/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.8144\n",
      "Epoch 55/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.8121\n",
      "Epoch 56/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8155\n",
      "Epoch 57/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.8155\n",
      "Epoch 58/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8200\n",
      "Epoch 59/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8178\n",
      "Epoch 60/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.8099\n",
      "Epoch 61/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.8099\n",
      "Epoch 62/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8245\n",
      "Epoch 63/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4306 - accuracy: 0.8065\n",
      "Epoch 64/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8200\n",
      "Epoch 65/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8144\n",
      "Epoch 66/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4234 - accuracy: 0.8076\n",
      "Epoch 67/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.8166\n",
      "Epoch 68/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8144\n",
      "Epoch 69/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8223\n",
      "Epoch 70/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8133\n",
      "Epoch 71/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8223\n",
      "Epoch 72/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8268\n",
      "Epoch 73/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8223\n",
      "Epoch 74/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.8301\n",
      "Epoch 75/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8313\n",
      "Epoch 76/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.8133\n",
      "Epoch 77/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8279\n",
      "Epoch 78/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8144\n",
      "Epoch 79/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8178\n",
      "Epoch 80/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8279\n",
      "Epoch 81/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8234\n",
      "Epoch 82/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8178\n",
      "Epoch 83/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8234\n",
      "Epoch 84/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.8301\n",
      "Epoch 85/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8268\n",
      "Epoch 86/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8121\n",
      "Epoch 87/200\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4115 - accuracy: 0.8178\n",
      "Epoch 88/200\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4088 - accuracy: 0.8279\n",
      "Epoch 89/200\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4115 - accuracy: 0.8234\n",
      "Epoch 90/200\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.4113 - accuracy: 0.8268\n",
      "Epoch 91/200\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8268\n",
      "Epoch 92/200\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4088 - accuracy: 0.8279\n",
      "Epoch 93/200\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.4328 - accuracy: 0.8088\n",
      "Epoch 94/200\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.4116 - accuracy: 0.8279\n",
      "Epoch 95/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8301\n",
      "Epoch 96/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8211\n",
      "Epoch 97/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8268\n",
      "Epoch 98/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8200\n",
      "Epoch 99/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8211\n",
      "Epoch 100/200\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.4039 - accuracy: 0.8279\n",
      "Epoch 101/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8200\n",
      "Epoch 102/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.8256\n",
      "Epoch 103/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8290\n",
      "Epoch 104/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8279\n",
      "Epoch 105/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8223\n",
      "Epoch 106/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8234\n",
      "Epoch 107/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4073 - accuracy: 0.8245\n",
      "Epoch 108/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8200\n",
      "Epoch 109/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8223\n",
      "Epoch 110/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8155\n",
      "Epoch 111/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8166\n",
      "Epoch 112/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8223\n",
      "Epoch 113/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8211\n",
      "Epoch 114/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8403\n",
      "Epoch 115/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8211\n",
      "Epoch 116/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8234\n",
      "Epoch 117/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8144\n",
      "Epoch 118/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8279\n",
      "Epoch 119/200\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.8279\n",
      "Epoch 120/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8223\n",
      "Epoch 121/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8256\n",
      "Epoch 122/200\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.4083 - accuracy: 0.8200\n",
      "Epoch 123/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 124/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4033 - accuracy: 0.8324\n",
      "Epoch 125/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.8268\n",
      "Epoch 126/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8290\n",
      "Epoch 127/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.8313\n",
      "Epoch 128/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8256\n",
      "Epoch 129/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8279\n",
      "Epoch 130/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8268\n",
      "Epoch 131/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8245\n",
      "Epoch 132/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8256\n",
      "Epoch 133/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8324\n",
      "Epoch 134/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8256\n",
      "Epoch 135/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8200\n",
      "Epoch 136/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8279\n",
      "Epoch 137/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8223\n",
      "Epoch 138/200\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8268\n",
      "Epoch 139/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8380\n",
      "Epoch 140/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8234\n",
      "Epoch 141/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3920 - accuracy: 0.8358\n",
      "Epoch 142/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8313\n",
      "Epoch 143/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3951 - accuracy: 0.8211\n",
      "Epoch 144/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8301\n",
      "Epoch 145/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8301\n",
      "Epoch 146/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8279\n",
      "Epoch 147/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8335\n",
      "Epoch 148/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8268\n",
      "Epoch 149/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4238 - accuracy: 0.8166\n",
      "Epoch 150/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8335\n",
      "Epoch 151/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8324\n",
      "Epoch 152/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3885 - accuracy: 0.8346\n",
      "Epoch 153/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3906 - accuracy: 0.8313\n",
      "Epoch 154/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3920 - accuracy: 0.8380\n",
      "Epoch 155/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8324\n",
      "Epoch 156/200\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.3962 - accuracy: 0.8279\n",
      "Epoch 157/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8335\n",
      "Epoch 158/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8313\n",
      "Epoch 159/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8346\n",
      "Epoch 160/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8414\n",
      "Epoch 161/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8346\n",
      "Epoch 162/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3888 - accuracy: 0.8279\n",
      "Epoch 163/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8200\n",
      "Epoch 164/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8346\n",
      "Epoch 165/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3925 - accuracy: 0.8268\n",
      "Epoch 166/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.8358\n",
      "Epoch 167/200\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.3967 - accuracy: 0.8234\n",
      "Epoch 168/200\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.4099 - accuracy: 0.8088\n",
      "Epoch 169/200\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.4025 - accuracy: 0.8279\n",
      "Epoch 170/200\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.3880 - accuracy: 0.8313\n",
      "Epoch 171/200\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.3856 - accuracy: 0.8380\n",
      "Epoch 172/200\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.3855 - accuracy: 0.8335\n",
      "Epoch 173/200\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.3867 - accuracy: 0.8313\n",
      "Epoch 174/200\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.3855 - accuracy: 0.8369\n",
      "Epoch 175/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3882 - accuracy: 0.8279\n",
      "Epoch 176/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3911 - accuracy: 0.8346\n",
      "Epoch 177/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8380\n",
      "Epoch 178/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8324\n",
      "Epoch 179/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.8425\n",
      "Epoch 180/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3884 - accuracy: 0.8358\n",
      "Epoch 181/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8335\n",
      "Epoch 182/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8324\n",
      "Epoch 183/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3865 - accuracy: 0.8346\n",
      "Epoch 184/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3887 - accuracy: 0.8335\n",
      "Epoch 185/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8313\n",
      "Epoch 186/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.8301\n",
      "Epoch 187/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8335\n",
      "Epoch 188/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8369\n",
      "Epoch 189/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8358\n",
      "Epoch 190/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3938 - accuracy: 0.8346\n",
      "Epoch 191/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8425\n",
      "Epoch 192/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.8380\n",
      "Epoch 193/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8358\n",
      "Epoch 194/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.8369\n",
      "Epoch 195/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3859 - accuracy: 0.8313\n",
      "Epoch 196/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.8391\n",
      "Epoch 197/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3945 - accuracy: 0.8279\n",
      "Epoch 198/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3925 - accuracy: 0.8268\n",
      "Epoch 199/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3824 - accuracy: 0.8335\n",
      "Epoch 200/200\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.8414\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "lossFn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "#Compile the model\n",
    "model.compile(loss=lossFn,optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "\n",
    "#Training the model\n",
    "history = model.fit(train_input,train_labels,epochs=200,batch_size=20)\n",
    "\n",
    "#Plot the results\n",
    "acc=history.history['accuracy']\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "plt.plot(epochs, acc, 'r')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.show()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model achieved an accuracy of about 83% after 200 epochs, which is quite good considering the amount of data we had! (also consider the missing values in the age column which were naively filled with the mean). However we also see that there was not much improvement after about 60 epochs and the accuracy hovered around 82-83%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Results\n",
    "Now that we have our trained model, we can perform the predictions on the final test set supplied from Kaggle (present in the Data/test.csv file). Again, we will have to preprocess/clean this file to make it the same shape as our model input vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the test.csv file\n",
    "test_data = pd.read_csv(test_data_path,delimiter=\",\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass       0\n",
       "Sex          0\n",
       "Age         86\n",
       "SibSp        0\n",
       "Parch        0\n",
       "Fare         1\n",
       "Embarked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping columns\n",
    "test_data = test_data.drop([\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"],axis=1)\n",
    "#Finding columns with null values\n",
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we cannot drop rows from our test data, both the Age and Fare missing values will be naively filled with the respective means. We will also one-hot encode the categorical values. Note that the order of the columns must be the same as our training input (since our model was trained with that specific order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>39.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>38.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>30.27259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  SibSp  Parch      Fare  female  male  Pclass_1  Pclass_2  \\\n",
       "0    34.50000      0      0    7.8292       0     1         0         0   \n",
       "1    47.00000      1      0    7.0000       1     0         0         0   \n",
       "2    62.00000      0      0    9.6875       0     1         0         1   \n",
       "3    27.00000      0      0    8.6625       0     1         0         0   \n",
       "4    22.00000      1      1   12.2875       1     0         0         0   \n",
       "..        ...    ...    ...       ...     ...   ...       ...       ...   \n",
       "413  30.27259      0      0    8.0500       0     1         0         0   \n",
       "414  39.00000      0      0  108.9000       1     0         1         0   \n",
       "415  38.50000      0      0    7.2500       0     1         0         0   \n",
       "416  30.27259      0      0    8.0500       0     1         0         0   \n",
       "417  30.27259      1      1   22.3583       0     1         0         0   \n",
       "\n",
       "     Pclass_3  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           1           0           1           0  \n",
       "1           1           0           0           1  \n",
       "2           0           0           1           0  \n",
       "3           1           0           0           1  \n",
       "4           1           0           0           1  \n",
       "..        ...         ...         ...         ...  \n",
       "413         1           0           0           1  \n",
       "414         0           1           0           0  \n",
       "415         1           0           0           1  \n",
       "416         1           0           0           1  \n",
       "417         1           1           0           0  \n",
       "\n",
       "[418 rows x 12 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fill missing values with mean\n",
    "test_data['Age'] = test_data['Age'].fillna(test_data['Age'].mean())\n",
    "test_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].mean())\n",
    "#Convert categorical values to one-hot encoding\n",
    "test_data = pd.concat([test_data, pd.get_dummies(test_data['Sex'])],axis=1)\n",
    "test_data = pd.concat([test_data, pd.get_dummies(test_data['Pclass'], prefix='Pclass')],axis=1)\n",
    "test_data = pd.concat([test_data, pd.get_dummies(test_data['Embarked'], prefix='Embarked')],axis=1)\n",
    "\n",
    "#Dropping original columns since they are now encoded\n",
    "test_data = test_data.drop(['Pclass','Sex','Embarked'], axis=1)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be our final test data for prediction. The shape is 418x12 as seen from above. We will convert these to NumPy arrays and feed them into the model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34.5       ,  0.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [47.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [62.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [38.5       ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [30.27259036,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [30.27259036,  1.        ,  1.        , ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = []\n",
    "\n",
    "for index,row in test_data.iterrows():\n",
    "    #Append all columns to input\n",
    "    test_input.append(row[:])\n",
    "\n",
    "#Convert to NP Array\n",
    "test_input = np.asarray(test_input)\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 12) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 12), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (None, 12).\n",
      "14/14 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 10:43:46.714948: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting the results\n",
    "test_pred = model.predict(test_input)\n",
    "test_final = (test_pred > 0.5).astype(int).reshape(test_input.shape[0])\n",
    "test_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our predictions, we will output them into the a new CSV file with the passengerId column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    280\n",
       "1    138\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the original test data file again to get passengerIds\n",
    "test_data = pd.read_csv(test_data_path,delimiter=\",\")\n",
    "output = pd.DataFrame({'PassengerId':test_data['PassengerId'], 'Survived':test_final})\n",
    "#Save the file\n",
    "output.to_csv('Data/predictions.csv',index=False)\n",
    "output['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Our model has predicted 151 survivors out of the 418 rows of test data. After uploading the CSV to kaggle to check our score, we achieved about 77% accuracy. Further improvements could be done by changing the preprocessing methods (such as filling in missing values, dropping columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save('PredictionModel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('tf_Dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4da46fc40f1915703b38afd3791e6a316bca5498ac50c4dc99c37cd966af4760"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
